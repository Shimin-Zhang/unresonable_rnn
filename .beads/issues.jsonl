{"id":"RNN-1","title":"RNN Learning Web App - Complete Course Implementation","description":"Build a custom web app to help working professionals learn about RNNs based on Karpathy's \"The Unreasonable Effectiveness of Recurrent Neural Networks\" blog post. The app will feature 11 modules (0-10), interactive elements, assessments, and supporting materials including learning paths for different audiences (managers, practitioners, time-constrained, interview prep).","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-15T17:13:19.699280345-08:00","updated_at":"2026-01-15T17:13:19.699280345-08:00","labels":["course","rnn","web-app"]}
{"id":"RNN-10","title":"Module 8: Limitations and the Path Forward","description":"Implement the limitations module covering 4 key RNN limitations: very long-range dependencies, sequential processing bottleneck, representation coupling (Karpathy quote), and training instability. Cover the Transformer revolution (2017+) and when to still use RNNs. Include comprehensive Build vs Buy decision framework for working professionals with decision tree and cost comparison table.","design":"Learning Techniques: Feedback (honest assessment), Self-Regulation (when-to-use checklist), Narrative Learning (transformer revolution), Adaptive Learning (RNN niche uses). Interactive elements: Long-Range Dependency Stress Test, Speed Comparison Benchmark (RNN vs Transformer), \"Should I Use an RNN?\" interactive flowchart, Sequence Model Timeline with milestones, Architecture Selection Exercise, \"Transformer Teaser\" preview.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-15T17:15:35.536007401-08:00","updated_at":"2026-01-15T17:15:35.536007401-08:00","labels":["decision-making","limitations","module","transformers"],"dependencies":[{"issue_id":"RNN-10","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:15:35.556728713-08:00","created_by":"shimin"}]}
{"id":"RNN-11","title":"Module 9: Implementation Deep Dive","description":"Implement the hands-on implementation module with three tracks: Track A (NumPy from scratch - 100 lines, Karpathy's minimal char-rnn), Track B (PyTorch production-ready LSTM with GPU training), Track C (Hugging Face fastest to production with GPT-2). Cover BPTT gradient equation, training tips (gradient clipping, Adam, dropout), and common failure modes with solutions table.","design":"Learning Techniques: Active Learning (code walkthroughs), Self-Regulation (training checklist), Feedback (debugging common failures), Scaffolding (progressive difficulty). Interactive elements: Progressive Coding Labs (Forward Pass → Loss → Backward → Full Loop), Bug Hunt challenges, Hyperparameter Grid Search Visualizer, Real-Time Training Dashboard with live loss curve and sample outputs.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-15T17:15:40.661598731-08:00","updated_at":"2026-01-15T17:15:40.661598731-08:00","labels":["code","implementation","module","pytorch"],"dependencies":[{"issue_id":"RNN-11","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:15:40.681150926-08:00","created_by":"shimin"}]}
{"id":"RNN-12","title":"Module 10: Capstone Project - Train Your Own Model","description":"Implement the capstone project module with 3 difficulty levels: Beginner (song lyrics, 500KB), Intermediate (code generator, 5MB, 80%+ parseable), Advanced (multi-author style, 10MB, human evaluation). Cover 5 project milestones: Data Preparation, Model Architecture, Training Loop, Evaluation, Presentation. Include gamification with achievement badges.","design":"Learning Techniques: Adaptive Learning (difficulty selection), Setting Goals (clear milestones), Gamification (badges: First Blood, Linguist, Interpreter, Creative Writer, Optimization Guru). Interactive elements: Project Template Selector, Dataset Explorer with upload, Gamified Milestone Checklist, Progress Dashboard, Class Leaderboard, Peer Review System, Sample Gallery, Project Presentation Mode, Achievement/Certificate System.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-15T17:15:45.783990501-08:00","updated_at":"2026-01-15T17:15:45.783990501-08:00","labels":["capstone","gamification","module","project"],"dependencies":[{"issue_id":"RNN-12","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:15:45.803529781-08:00","created_by":"shimin"}]}
{"id":"RNN-13","title":"Learning Paths Navigation System","description":"Implement the learning paths navigation that routes users to appropriate modules based on their role and goals. Four paths: Path A (Conceptual - Managers/PMs/Executives: Modules 0,1,3,5,7,8), Path B (Full Practitioner - ML Engineers: all modules in order), Path C (Quick Wins - Time-constrained: Modules 0,1,2,4.1-4.3,8), Path D (Interview Prep - Job seekers: Modules 0,2,3,7,8 with focus on key interview topics).","design":"Include path selection UI at course start, progress tracking per path, ability to switch paths, and recommendations based on time availability. Reference Appendix E for interview-specific content in Path D.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:16:39.293277239-08:00","updated_at":"2026-01-15T17:16:39.293277239-08:00","labels":["navigation","personalization","ux"],"dependencies":[{"issue_id":"RNN-13","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:16:39.311149012-08:00","created_by":"shimin"}]}
{"id":"RNN-14","title":"Assessment System - Quizzes and Reflection","description":"Implement the assessment strategy with formative assessments (end-of-section quizzes 3-5 questions each, coding exercises with automated tests, peer review) and summative assessments (6 reflection prompts covering surprising learnings, vanishing gradients explanation, applications, attention importance, RNN vs Transformer choice, connection to modern LLMs). Include gamified final challenge with community voting.","design":"Learning Techniques: Feedback (continuous checks), Metacognition (reflection prompts), Gamification (badges, certificates, community vote). Include spaced repetition review prompts at module transitions.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-15T17:16:44.445893379-08:00","updated_at":"2026-01-15T17:16:44.445893379-08:00","labels":["assessment","gamification","quizzes"],"dependencies":[{"issue_id":"RNN-14","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:16:44.462571158-08:00","created_by":"shimin"}]}
{"id":"RNN-15","title":"Appendix A: Prerequisites Diagnostic \u0026 Refresher","description":"Implement the prerequisites section with diagnostic quizzes: Math Readiness Quiz (5 questions on matrices, derivatives, chain rule, softmax, tanh) and Python/NumPy Readiness Quiz (5 questions on dot product, reshaping, operators, indexing, argmax). Include mini-refreshers: Calculus Refresher (15 min), Linear Algebra Refresher (15 min), NumPy Crash Course (30 min) with softmax implementation exercise.","design":"Adaptive routing based on quiz scores (5/5 = proceed, 3-4 = calculus refresher, 0-2 = full math foundation). Include code snippets for NumPy operations and practice exercises.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-15T17:16:49.60865842-08:00","updated_at":"2026-01-15T17:16:49.60865842-08:00","labels":["appendix","math","prerequisites"],"dependencies":[{"issue_id":"RNN-15","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:16:49.62635899-08:00","created_by":"shimin"}]}
{"id":"RNN-16","title":"Appendix B-C: Further Reading \u0026 Glossary","description":"Implement Appendix B (Further Reading with foundational papers cited in Karpathy's blog - LSTM, Graves thesis, Sutskever, Mikolov; attention/memory papers - Bahdanau, NTM, Memory Networks; modern extensions - Colah's blog, Transformers, GPT-2; code resources - char-rnn, min-char-rnn gist) and Appendix C (Glossary with 15+ terms including Attention, BPTT, Cell State, Encoder-Decoder, Hidden State, NTM, One-Hot, Perplexity, Seq2Seq, Soft/Hard Attention, Temperature, Transformer, Turing Complete, Vanishing Gradient).","design":"Include hyperlinks to papers and resources. Glossary should support hover tooltips throughout the app (connects to Module 0's Jargon Translator feature).","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-15T17:16:54.766271516-08:00","updated_at":"2026-01-15T17:16:54.766271516-08:00","labels":["appendix","glossary","resources"],"dependencies":[{"issue_id":"RNN-16","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:16:54.782969934-08:00","created_by":"shimin"}]}
{"id":"RNN-17","title":"Appendix D: Quick Reference Cheat Sheets","description":"Implement printable/downloadable cheat sheets: RNN Equations Cheat Sheet (hidden state update, output, softmax, cross-entropy with ASCII box art), LSTM Cheat Sheet (all 6 equations with key insight about cell state highway), Hyperparameter Starting Points table (hidden size, layers, learning rate, batch size, sequence length, dropout, gradient clip with \"Tune If...\" guidance), Temperature Guide table (ranges 0-0.3, 0.5-0.7, 0.8-1.0, 1.0+ with effects and use cases).","design":"Design for print-friendly PDF export. Include downloadable resources section with links. ASCII art formatting for terminal-style presentation.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-15T17:16:59.89416023-08:00","updated_at":"2026-01-15T17:16:59.89416023-08:00","labels":["appendix","cheatsheet","reference"],"dependencies":[{"issue_id":"RNN-17","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:16:59.910570034-08:00","created_by":"shimin"}]}
{"id":"RNN-18","title":"Appendix E: Interview Preparation Guide","description":"Implement the interview prep guide with 6 common interview questions and model answers: Q1 (explain RNN with follow-up on weight matrices), Q2 (vanishing gradient and LSTM solution), Q3 (attention and importance), Q4 (RNN vs Transformer decision), Q5 (implement RNN forward pass in code), Q6 (temperature in text generation). Include Portfolio Project Talking Points template (Problem, Approach, Challenge, Results, What I Learned).","design":"Format answers for quick review before interviews. Include code snippets for implementation questions. Connect to Path D (Interview Prep Track) for integrated learning experience.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-15T17:17:05.020917379-08:00","updated_at":"2026-01-15T17:17:05.020917379-08:00","labels":["appendix","career","interview"],"dependencies":[{"issue_id":"RNN-18","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:17:05.036853708-08:00","created_by":"shimin"}]}
{"id":"RNN-19","title":"Appendix F: Downloadable Resources","description":"Implement the downloadable resources system: RNN Equations Poster (PDF), LSTM Gate Diagram (PNG), Hyperparameter Tuning Flowchart (PDF), Code Templates (GitHub links for each implementation track), Flashcards (Anki deck export for spaced repetition of key concepts).","design":"Create download page with preview thumbnails. Generate appropriate file formats. Consider hosting code templates in companion GitHub repo.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-15T17:17:10.150318683-08:00","updated_at":"2026-01-15T17:17:10.150318683-08:00","labels":["appendix","downloads","resources"],"dependencies":[{"issue_id":"RNN-19","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:17:10.166660819-08:00","created_by":"shimin"}]}
{"id":"RNN-2","title":"Module 0: Executive Context - Why This Matters in 2024+","description":"Implement the executive context module that provides historical context of RNNs in AI development, connections to modern LLMs, and stakeholder communication strategies. Includes AI timeline from 1980s to present, industry applications table, and explanations for different audiences (dinner party, executives, ROI).","design":"Learning Techniques: Narrative Learning (AI timeline story), Setting Goals (industry applications), Metacognition (reflection prompts). Interactive elements include: \"Find Your Use Case\" Quiz, AI Timeline Explorer, Jargon Translator hover tooltips.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:14:04.440426686-08:00","updated_at":"2026-01-15T17:14:04.440426686-08:00","labels":["executive","module","narrative"],"dependencies":[{"issue_id":"RNN-2","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:14:04.457813143-08:00","created_by":"shimin"}]}
{"id":"RNN-20","title":"Web App Foundation \u0026 Tech Stack Setup","description":"Set up the core web application infrastructure for the RNN learning platform. Choose and configure appropriate tech stack (React/Next.js or similar), set up project structure, configure build system, and establish component architecture. Include responsive design framework, routing, and state management.","design":"Consider: Static site generation for fast loading, LaTeX rendering library (KaTeX/MathJax), syntax highlighting for code blocks, markdown rendering. Design for progressive enhancement and accessibility.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T17:17:57.69534155-08:00","updated_at":"2026-01-15T21:00:58.734899408-08:00","closed_at":"2026-01-15T21:00:58.734899408-08:00","labels":["frontend","infrastructure","setup"],"dependencies":[{"issue_id":"RNN-20","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:17:57.712991254-08:00","created_by":"shimin"}]}
{"id":"RNN-21","title":"LaTeX Equation Rendering System","description":"Implement the LaTeX equation rendering system with color-coded elements and symbol tables. All equations should display with color-coded individual elements (using specified colors from lesson plan) with accompanying notation tables explaining each symbol. Support both inline and block equations.","design":"Use KaTeX for fast rendering. Create reusable Equation component with props for: equation string, color mapping, symbol definitions. Symbol tables should appear below/beside equations. Support responsive sizing for mobile.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T17:18:02.867552748-08:00","updated_at":"2026-01-15T21:11:03.919500385-08:00","closed_at":"2026-01-15T21:11:03.919500385-08:00","labels":["component","latex","math"],"dependencies":[{"issue_id":"RNN-21","depends_on_id":"RNN-20","type":"blocks","created_at":"2026-01-15T17:18:02.88460771-08:00","created_by":"shimin"}]}
{"id":"RNN-22","title":"Interactive Code Editor Component","description":"Implement a reusable interactive code editor component for the coding labs throughout the course. Support Python syntax highlighting, live execution (via Pyodide or similar), automated test running, and real-time feedback. Include features for progressive hints and solution reveal.","design":"Consider Monaco Editor or CodeMirror. Integrate with Pyodide for browser-based Python execution. Create test harness for automated grading. Support difficulty indicators (⭐ ratings). Include \"Check Answer\" and \"Show Solution\" buttons.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T17:18:08.067076258-08:00","updated_at":"2026-01-15T21:40:02.250758302-08:00","closed_at":"2026-01-15T21:40:02.250758302-08:00","labels":["code","component","interactive"],"dependencies":[{"issue_id":"RNN-22","depends_on_id":"RNN-20","type":"blocks","created_at":"2026-01-15T17:18:08.08478336-08:00","created_by":"shimin"}]}
{"id":"RNN-23","title":"Quiz \u0026 Assessment Component System","description":"Implement reusable quiz components for formative assessments throughout modules. Support multiple choice, drag-and-drop matching, fill-in-the-blank, and short answer formats. Include immediate feedback, explanation popups, score tracking, and spaced repetition prompts at module transitions.","design":"Create Quiz component with configurable question types. Store user progress in local storage or backend. Support \"review before next module\" prompts. Include visual feedback (green/red indicators, confetti for perfect scores).","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-15T17:18:13.217423616-08:00","updated_at":"2026-01-15T17:18:13.217423616-08:00","labels":["assessment","component","quiz"],"dependencies":[{"issue_id":"RNN-23","depends_on_id":"RNN-20","type":"blocks","created_at":"2026-01-15T17:18:13.234593133-08:00","created_by":"shimin"}]}
{"id":"RNN-24","title":"Interactive Visualization Framework","description":"Implement the visualization framework for neural network diagrams, data flow animations, heatmaps, and interactive sliders. This powers the Hidden State Visualizer, Gradient Flow Simulator, LSTM Gate Playground, Attention Heatmaps, and Neuron Activation displays across multiple modules.","design":"Use D3.js or similar for custom visualizations. Create reusable components: NetworkDiagram, HeatmapDisplay, AnimatedDataFlow, SliderControl, TimelineChart. Support real-time updates and user interaction. Consider performance for complex animations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-15T17:18:18.352700185-08:00","updated_at":"2026-01-15T17:18:18.352700185-08:00","labels":["component","d3","visualization"],"dependencies":[{"issue_id":"RNN-24","depends_on_id":"RNN-20","type":"blocks","created_at":"2026-01-15T17:18:18.368644049-08:00","created_by":"shimin"}]}
{"id":"RNN-25","title":"Progress Tracking \u0026 Gamification System","description":"Implement user progress tracking and gamification features: module completion tracking, achievement badges (First Blood, Linguist, Interpreter, Creative Writer, Optimization Guru, etc.), progress dashboards per learning path, leaderboards, and certificate generation system.","design":"Store progress in local storage (or optional backend for persistence). Badge unlock notifications. Progress visualization showing % complete per module and overall. Certificate PDF generation with personalized name, completion date, and skills demonstrated. Consider optional user accounts for persistence.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-15T17:18:23.504970113-08:00","updated_at":"2026-01-15T17:18:23.504970113-08:00","labels":["badges","gamification","progress"],"dependencies":[{"issue_id":"RNN-25","depends_on_id":"RNN-20","type":"blocks","created_at":"2026-01-15T17:18:23.52209674-08:00","created_by":"shimin"}]}
{"id":"RNN-26","title":"Stakeholder Explanation Cards Component","description":"Implement reusable \"Explain to Your Stakeholders\" card components used throughout modules. Each module has explanations for different audiences: Dinner Party Version (casual), For Your Manager (business-focused), Technical Interview Answer (precise), ROI Statement, etc. These appear as toggleable/tabbed content sections.","design":"Create ExplanationCards component with audience tabs (Casual, Business, Technical, Interview). Include copy-to-clipboard functionality for easy sharing. Design for quick scanning with key phrases highlighted. Mobile-friendly accordion on smaller screens.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-15T17:18:28.637459675-08:00","updated_at":"2026-01-15T17:18:28.637459675-08:00","labels":["communication","component","content"],"dependencies":[{"issue_id":"RNN-26","depends_on_id":"RNN-20","type":"blocks","created_at":"2026-01-15T17:18:28.654900214-08:00","created_by":"shimin"}]}
{"id":"RNN-3","title":"Module 1: Why Sequences Matter","description":"Implement the module explaining the limitation of vanilla neural networks and why RNNs solve the variable-length sequence problem. Cover the 5 sequence architecture types (one-to-one, one-to-many, many-to-one, many-to-many synced, many-to-many encoder-decoder). Include historical context on why RNNs suddenly worked in 2015 and Turing completeness discussion.","design":"Learning Techniques: Narrative Learning (story hook about movie reviews), Curiosity (\"What if a neural network could remember?\"), Scaffolding (5 architecture types table), Multimodal (animated data flow diagrams), Metacognition (understanding timing). Interactive elements: Sequence Sorter drag-drop, \"Spot the Sequence\" game, reflection prompts, quick quiz.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:14:09.554720813-08:00","updated_at":"2026-01-15T17:14:09.554720813-08:00","labels":["fundamentals","module","sequences"],"dependencies":[{"issue_id":"RNN-3","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:14:09.57185798-08:00","created_by":"shimin"}]}
{"id":"RNN-4","title":"Module 2: The RNN Architecture - Building Memory into Networks","description":"Implement the core RNN architecture module with the vanilla RNN equations. Present the hidden state update equation h_t = tanh(W_hh·h_{t-1} + W_xh·x_t + b_h), output computation y_t = W_hy·h_t + b_y, and softmax for probabilities. Include color-coded LaTeX equations with symbol tables and 3 examples for each equation. Cover Karpathy's insight: \"training RNNs is optimization over programs.\"","design":"Learning Techniques: Constructivism (build from for-loops), Cognitive Load (layered equation presentation), Scaffolding (step-by-step equations), Multimodal (unrolling animations), Metacognition (trace information flow). Interactive elements: \"What Comes Next?\" prediction game, Hidden State Visualizer, RNN Step Function code lab, hand calculation exercises, \"What If?\" explorer, Speed Round challenge.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:14:14.665210573-08:00","updated_at":"2026-01-15T17:14:14.665210573-08:00","labels":["architecture","equations","math","module"],"dependencies":[{"issue_id":"RNN-4","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:14:14.684660795-08:00","created_by":"shimin"}]}
{"id":"RNN-5","title":"Module 3: The Vanishing Gradient Problem \u0026 LSTMs","description":"Implement the module on vanishing gradients and LSTM solution. Cover gradient multiplication through time with examples (0.5^20, 2^20, 1.0^20). Present LSTM cell state equation C_t = f_t ⊙ C_{t-1} + i_t ⊙ C̃_t with the three gates (forget, input, output). Include color-coded LaTeX with symbol tables and practical examples (subject-verb agreement, bracket matching, sentiment with negation).","design":"Learning Techniques: Narrative Learning (telephone game analogy), Cognitive Load (simplified gradient math), Scaffolding (build LSTM piece by piece), Curiosity (why separate gates?), Metacognition (conveyor belt analogy). Interactive elements: Gradient Flow Simulator, \"Telephone Game\" Demo, LSTM Gate Playground with sliders, Predict-Then-Reveal gate activation, Gate Matching Quiz, Debug the LSTM challenge.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:14:19.782659475-08:00","updated_at":"2026-01-15T17:14:19.782659475-08:00","labels":["gradients","lstm","math","module"],"dependencies":[{"issue_id":"RNN-5","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:14:19.801668555-08:00","created_by":"shimin"}]}
{"id":"RNN-6","title":"Module 4: Character-Level Language Modeling","description":"Implement the character-level modeling module covering next-character prediction, \"hello\" example from the blog, one-hot encoding, cross-entropy loss, and temperature-scaled sampling. Present loss equation L = -Σlog p(c_t+1|c_1...c_t) and temperature softmax p_i = exp(y_i/τ)/Σexp(y_j/τ) with color-coded LaTeX. Connect directly to modern AI tools (ChatGPT/Claude temperature settings).","design":"Learning Techniques: Active Learning (prediction games), Constructivism (build from fundamentals), Cognitive Load (step-by-step training), Feedback (side-by-side temperature samples), Scaffolding (vocabulary example). Interactive elements: \"Guess the Next Character\" game, Temperature Playground with 3 live outputs, Training Timelapse slider, Loss Function code lab, Sampling code lab, Progressive training challenges with perplexity goals.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:14:24.898000289-08:00","updated_at":"2026-01-15T17:14:24.898000289-08:00","labels":["char-rnn","module","sampling","training"],"dependencies":[{"issue_id":"RNN-6","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:14:24.918679491-08:00","created_by":"shimin"}]}
{"id":"RNN-7","title":"Module 5: Experiments - What Can RNNs Learn?","description":"Implement the experiments module showcasing Karpathy's char-rnn experiments: Paul Graham essays (baseline), Shakespeare (4.4MB), Wikipedia (100MB Hutter Prize), LaTeX (16MB algebraic geometry), Linux kernel source (474MB C code), and Baby Names (8,000 names). Include actual sample outputs from the blog. Cover training dynamics showing progression from iteration 100 to 2000+ and neuron visualization (URL detector, quote tracker, bracket cell, position counter).","design":"Learning Techniques: Curiosity (can NN learn Shakespeare/LaTeX/code?), Narrative Learning (discovery stories), Metacognition (model learns simple before complex), Active Learning (which names sound real?), Multimodal (neuron activation heatmaps). Interactive elements: Live Demo Gallery for each experiment, Iteration Scrubber with sample evolution, Neuron Detective game, Activation Heatmap Explorer, \"Your Own Dataset\" training, \"Spot the Bug\" error analysis.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:15:20.108702279-08:00","updated_at":"2026-01-15T17:15:20.108702279-08:00","labels":["experiments","module","visualization"],"dependencies":[{"issue_id":"RNN-7","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:15:20.125302863-08:00","created_by":"shimin"}]}
{"id":"RNN-8","title":"Module 6: Beyond Text - RNNs in Vision, Speech, and Translation","description":"Implement the multimodal applications module covering CNN+RNN for image captioning, encoder-decoder for machine translation, speech recognition pipeline, and visual question answering. Present encoder-decoder equations h_enc = RNN_enc(x_1...x_n), y_t = RNN_dec(h_enc, y_1...y_{t-1}). Show how RNNs became the \"glue\" connecting different AI capabilities.","design":"Learning Techniques: Narrative Learning (CNN+RNN breakthrough), Constructivism (build on RNN knowledge), Multimodal (visual pipelines), Metacognition (RNNs as universal interface). Interactive elements: Image Captioning Demo with feature highlighting, Translation Sandbox with context vector visualization, Architecture Matching drag-drop, \"Build the Pipeline\" exercise, Model Size Explorer with quality/cost tradeoffs, Cross-Domain Brainstorm reflection.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-15T17:15:25.245828956-08:00","updated_at":"2026-01-15T17:15:25.245828956-08:00","labels":["module","multimodal","translation","vision"],"dependencies":[{"issue_id":"RNN-8","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:15:25.265737112-08:00","created_by":"shimin"}]}
{"id":"RNN-9","title":"Module 7: Attention Mechanisms - The Most Important Innovation","description":"Implement the attention module covering the bottleneck problem, attention mechanism equations α_{t,i} = softmax(e_{t,i}) and c_t = Σα_{t,i}·h_i with color-coded LaTeX. Cover soft vs hard attention comparison, Neural Turing Machines, Memory Networks. Emphasize Karpathy's assessment: attention is \"the most interesting recent architectural innovation\" and the bridge to Transformers.","design":"Learning Techniques: Scaffolding (intuition before math), Curiosity (what if decoder could look back?), Cognitive Load (soft vs hard comparison table), Metacognition (stepping stones to transformers). Interactive elements: Translation Attention Visualizer with heatmap, Image Attention Demo highlighting regions, Attention Weight Calculator, Implement Attention code lab, Soft vs Hard side-by-side, Neural Turing Machine Simulator, Attention Debugging challenge.","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-15T17:15:30.388967239-08:00","updated_at":"2026-01-15T17:15:30.388967239-08:00","labels":["attention","math","module","transformers"],"dependencies":[{"issue_id":"RNN-9","depends_on_id":"RNN-1","type":"blocks","created_at":"2026-01-15T17:15:30.409302803-08:00","created_by":"shimin"}]}
